{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import datetime\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "class CSVReader():\n",
    "    def read_csv_data(self, filename: str) -> pl.DataFrame:\n",
    "        # read the column names from the file\n",
    "        with open(filename, 'r') as file:\n",
    "            for _ in range(5):\n",
    "                file.readline()\n",
    "            column_names = file.readline().strip().split(';')\n",
    "\n",
    "        # read the data into a polars dataframe\n",
    "        df = pl.read_csv(filename, skip_rows=5, separator=';', skip_rows_after_header=2, encoding=\"ISO-8859-1\", ignore_errors=True) #errors cause no actual issues\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def replace_unicode_chars(self, df: pl.DataFrame, col_name: str) -> pl.Series:\n",
    "        # Get the column to be iterated\n",
    "        col = df[col_name]\n",
    "        regex = re.compile(r\"\\\\u(\\d+)\\?\")\n",
    "        # Iterate through each row in the column\n",
    "        for i, val in enumerate(col):\n",
    "            # Check if the value contains a unicode character\n",
    "            match = regex.search(val)\n",
    "            if match:\n",
    "                # Extract the unicode character code from the string\n",
    "                hex_code = val.split(\"\\\\u\")[1].split(\"?\")[0]\n",
    "                # Convert the hex code to an integer and then to its corresponding unicode character\n",
    "                char = chr(int(hex_code))\n",
    "\n",
    "                # Replace the original value with the new value containing the unicode character\n",
    "                col[i] = val.replace(match.group(), char)\n",
    "\n",
    "        return col\n",
    "\n",
    "\n",
    "    def strip_strings(self, x: str) -> str:\n",
    "        if isinstance(x, str):\n",
    "            return x.strip()\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "    def rtf_data_processing(self, df: pl.DataFrame) -> pl.DataFrame:\n",
    "        df = df.with_columns([\n",
    "            pl.when(pl.col('Year(s) Weapon of Order').str.contains(r'\\(.*\\)'))\n",
    "            .then(pl.lit(\"Yes\"))\n",
    "            .otherwise(pl.lit(\"No\"))\n",
    "            .alias(\"is estimated year order\")\n",
    "        ])\n",
    "\n",
    "        df = df.with_columns([\n",
    "            pl.col('Year(s) Weapon of Order').str.replace_all(r\"[()]\", \"\").alias('Year(s) Weapon of Order').cast(pl.Int64)\n",
    "        ])\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def joined_table(self, df_rtf, csv_df):\n",
    "        processed_dF = self.rtf_data_processing(df_rtf)\n",
    "        # remove possible spaces for the designations\n",
    "        csv_df = csv_df.with_columns(csv_df['Designation'].str.strip_chars())\n",
    "\n",
    "        processed_dF = processed_dF.with_columns(self.replace_unicode_chars(df_rtf, \"No. Designation\"))\n",
    "        processed_dF = processed_dF.with_columns(self.replace_unicode_chars(df_rtf, \"No. Comments\"))\n",
    "\n",
    "        joined_dF = csv_df.join(processed_dF,\n",
    "                            left_on=['Seller', 'Buyer',\n",
    "                                        'Designation', 'Order date',\n",
    "                                        ],\n",
    "                            right_on=[\"Supplier\", \"Recipient\",\n",
    "                                        \"No. Designation\", 'Year(s) Weapon of Order',\n",
    "                                        ],\n",
    "                            how=\"left\")\n",
    "        joined_dF = joined_dF.select(\n",
    "            ['Deal ID', 'Seller', 'Buyer', 'Designation', 'Description', 'Armament category', 'Order date',\n",
    "            'Order date is estimate', 'Numbers delivered', 'Numbers delivered is estimate', 'Delivery year',\n",
    "            'Delivery year is estimate', 'Status', 'SIPRI estimate', 'TIV deal unit', 'TIV delivery values',\n",
    "            'Local production', 'No. Comments'])\n",
    "\n",
    "        return joined_dF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1,)\n",
      "Series: 'Year(s) Weapon of Order' [bool]\n",
      "[\n",
      "\tfalse\n",
      "] dash == True\n",
      "missing comments: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Radur\\AppData\\Local\\Temp\\ipykernel_23644\\1216642364.py:70: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
      "  df = pl.DataFrame(rows, schema=[\"Supplier\", \"Recipient\", \"Ordered\", \"No. Designation\", \"Weapon Description\",\n"
     ]
    }
   ],
   "source": [
    "def readFile(fileToRead):\n",
    "    with open(fileToRead, 'r') as file:\n",
    "        result = file.readlines()\n",
    "        file.close()\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "# def read_file_binary(file_to_read):\n",
    "#     with open(file_to_read, 'rb') as file:\n",
    "#         contents = file.read().decode()\n",
    "#     return contents.split(\"\\r\\n\")\n",
    "\n",
    "\n",
    "dateGatheredString = 'Information generated:\\\\b0  '\n",
    "date = None\n",
    "searchFor = 'Date'\n",
    "country = None\n",
    "\n",
    "rows = []\n",
    "\n",
    "# TODO - This needs to find the file in the folder as a normal rtf with no special name\n",
    "rtfLines = readFile('Trade-Register-1950-2021-downloaded.rtf')\n",
    "for line in rtfLines:\n",
    "    # At the start we only want to look for the date\n",
    "    if searchFor == 'Date':\n",
    "        if dateGatheredString in line:\n",
    "            # Line looks like this: 'SIPRI Arms Transfers Database\\par \\b Information generated:\\b0  10 March 2023\\par \\par }'\n",
    "            date = line.split(dateGatheredString)[1].split(\"\\\\par\")[0]\n",
    "\n",
    "            # Now we have date we could look to find the headings of our table\n",
    "            # But will assume that the headings are always in the same place and so will just hard code them below\n",
    "            searchFor = 'Data'\n",
    "\n",
    "    elif searchFor == 'Data':\n",
    "        # We are looking for the data now and each line of data starts with a '{\\b'\n",
    "        # Use \\\\ as \\ is an escape character so need to first escape it\n",
    "        # Example: '{\\b Albania}\\par{\\b R:} Burkina Faso\\tab (12)\\tab PM-43 120mm\\tab mortar\\tab (2011)\\tab 2011\\tab 12\\tab Probably second-hand\\par\\pard\\plain \\s6\\sb40\\sl40\\brdrt\\brdrs'\n",
    "\n",
    "        # There are another format which starts with \\par{\\b, it is a kind of continue from the previous line.\n",
    "        # other formats basically the same, just keep the supplier read from the previous line\n",
    "        # and skip line.split('}\\\\par{\\\\b R:} ')[1] this\n",
    "        # Example: '\\par{\\b     } Iran\\tab (413)\\tab BMP-2\\tab IFV\\tab 1991\\tab 1993-2001\\tab (413)\\tab 1500 ordered but probably only 413 delivered; 82 delivered direct, rest assembled in Iran; Iranian designation possibly BMT-2'\n",
    "        if line[0:3] == r'{\\b' or line[0:7] == r\"\\par{\\b\":\n",
    "            if line[0:3] == '{\\\\b':\n",
    "                supplier = line.split('}\\\\par')[0].split('{\\\\b ')[1]\n",
    "                recipients = line.split('}\\\\par{\\\\b R:} ')[1].split('{\\\\b     } ')\n",
    "            else:\n",
    "                recipients = line.split('{\\\\b     } ')[1:]\n",
    "\n",
    "            for recipient in recipients:\n",
    "                # Two cases\n",
    "                # 1. Recipient contains a country\n",
    "                # 2. Recipient contains '\\tab\\tab' Which means to use the previous country\n",
    "                if recipient[0:8] == '\\\\tab\\\\tab':\n",
    "                    # Use the previous country\n",
    "                    countryData = recipient.split('\\\\tab\\\\tab')[1].split('\\\\tab')\n",
    "                    pass\n",
    "                else:\n",
    "                    country = recipient.split('\\\\tab')[0]\n",
    "                    countryData = recipient.split('\\\\tab')[1:]\n",
    "                row = [supplier, country, countryData[0], countryData[1], countryData[2], countryData[3], # type: ignore\n",
    "                       countryData[4],\n",
    "                       countryData[5], countryData[6].split('\\\\par')[0]]\n",
    "                rows.append(\n",
    "                    [element.strip() for element in row])\n",
    "\n",
    "\n",
    "# Hard Coded as getting the actual value is a bit of a pain\n",
    "df = pl.DataFrame(rows, schema=[\"Supplier\", \"Recipient\", \"Ordered\", \"No. Designation\", \"Weapon Description\",\n",
    "\n",
    "                                    \"Year(s) Weapon of Order\", \"Year Delivery\", \"Of Delivered\", \"No. Comments\"])\n",
    "df.write_csv(\"processed_rtf.csv\")\n",
    "# TODO Set the type of the columns\n",
    "# print(df)\n",
    "\n",
    "# find if the unique values in 'col1' contain '-'\n",
    "contains_dash = df[\"Year(s) Weapon of Order\"].str.contains('-').unique()\n",
    "\n",
    "print(f\"contains dashes: {contains_dash}\")\n",
    "missing_count = df['No. Comments'].is_null().sum()\n",
    "print(f\"missing comments: {missing_count}\")\n",
    "\n",
    "reader = CSVReader()\n",
    "\n",
    "csv_df = reader.read_csv_data(\"../csvReader/data.txt\")\n",
    "joinedDF = reader.joined_table(df, csv_df)\n",
    "joinedDF.write_csv(\"joined_data_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
